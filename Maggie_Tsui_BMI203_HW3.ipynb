{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import *\n",
    "class NeuralNetwork:\n",
    "    \"\"\"Class that creates a NN and includes methods to train and test\"\"\"\n",
    "    def __init__(self, setup=[[68,25,\"sigmoid\",0],[25,1,\"sigmoid\",0]],lr=.05,seed=1,error_rate=0,bias=0,iters=500,lamb=.00001,simple=0):\n",
    "        #Note - these paramaters are examples, not the required init function parameters\n",
    "        self._lr = lr\n",
    "        self._seed = seed\n",
    "        self._error_rate = error_rate\n",
    "        self._bias = bias\n",
    "        self._iters = iters\n",
    "        self._lamb = lamb\n",
    "        self._simple = simple\n",
    "        \n",
    "\n",
    "        # network is represented as a list of layers,\n",
    "        # where layers are a list of nodes, where nodes\n",
    "        # are a list of weights.\n",
    "        # weights = [ [[w1,w2...], [w1,w2...]] <- layer1\n",
    "        #             [[w1,w2...], [w1,w2...]] <- layer2\n",
    "        #           ]\n",
    "        weights = []\n",
    "        outputs = []\n",
    "        change = []\n",
    "        \n",
    "        # initialize the given number of layers with weights\n",
    "        for layer in setup:\n",
    "            weights.append(self.make_weights(n_inputs=layer[0],n_nodes=layer[1]))\n",
    "            outputs.append([0] * layer[1])\n",
    "            change.append([0] * layer[1])\n",
    "        \n",
    "        self._weights = weights\n",
    "        self._outputs = outputs\n",
    "        self._change = change\n",
    "        \n",
    "    @property\n",
    "    def lr(self):\n",
    "        return self._lr\n",
    "\n",
    "    @lr.setter\n",
    "    def lr(self, lr):\n",
    "        self._lr = lr\n",
    "\n",
    "    @property\n",
    "    def bias(self):\n",
    "        return self._bias\n",
    "\n",
    "    @bias.setter\n",
    "    def bias(self, bias):\n",
    "        self._bias = bias \n",
    "    \n",
    "    @property\n",
    "    def seed(self):\n",
    "        return self._seed\n",
    "\n",
    "    @seed.setter\n",
    "    def seed(self, seed):\n",
    "        self._seed = seed \n",
    "    \n",
    "    @property\n",
    "    def outputs(self):\n",
    "        return self._outputs\n",
    "\n",
    "    @outputs.setter\n",
    "    def outputs(self, outputs):\n",
    "        self._outputs = outputs \n",
    "        \n",
    "    @property\n",
    "    def change(self):\n",
    "        return self._change\n",
    "\n",
    "    @change.setter\n",
    "    def change(self, change):\n",
    "        self._change = change \n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        return self._weights\n",
    "\n",
    "    @weights.setter\n",
    "    def weights(self, weights):\n",
    "        self._weights = weights \n",
    "        \n",
    "        \n",
    "    def make_weights(self,n_inputs, n_nodes):\n",
    "        \"\"\"\n",
    "        Generates random weights for the network initialization\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        n_inputs\n",
    "            Number of input nodes to this layer\n",
    "        n_nodes\n",
    "            Number of nodes to generate weights for\n",
    "            \n",
    "        Returns\n",
    "        ---------\n",
    "        Layer with random weights initialized for each node\n",
    "        \"\"\"\n",
    "        #seed(self.seed)\n",
    "        layer = []\n",
    "        \n",
    "        # Get n_inputs random float between -1 and 1 for each node\n",
    "        for i in range(n_nodes):\n",
    "            node_weights = [uniform(-1, 1) for j in range(n_inputs + 1)]\n",
    "            #node_weights.append(self.bias) # add bias at end\n",
    "            layer.append(node_weights)\n",
    "        \n",
    "        return layer\n",
    "\n",
    "    def feedforward(self, data):\n",
    "        \"\"\"\n",
    "        Takes in data and passes it through the NN\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        data\n",
    "            One datapoint\n",
    "            \n",
    "        Returns\n",
    "        ---------\n",
    "        The output(s) of the final layer in the network\n",
    "        \"\"\"\n",
    "        inputs = data\n",
    "        \n",
    "        # pass data through all layers\n",
    "        for layer in range(len(self.weights)):\n",
    "            next_inputs = []\n",
    "            for node in range(len(self.weights[layer])):\n",
    "                sum = 0\n",
    "                for i in range(len(inputs)): # multiply inputs by weights and add to sum\n",
    "                    sum += inputs[i]*self.weights[layer][node][i]\n",
    "                    \n",
    "                sum += self.weights[layer][node][-1] # add bias\n",
    "                output = sigmoid(sum) # Apply activation function\n",
    "                self.outputs[layer][node] = output\n",
    "                next_inputs.append(output)\n",
    "            inputs = next_inputs\n",
    "        \n",
    "        # inputs should now be the final layer output\n",
    "        return inputs\n",
    "    \n",
    "    def backprop(self, true_values, data):\n",
    "        \"\"\"\n",
    "        Calculates the loss and gradient for each output node.\n",
    "        Propagates the gradient through the network and records\n",
    "        the error for each node.\n",
    "        \n",
    "        Parameters\n",
    "        ---------\n",
    "        true_values\n",
    "            true classification of example\n",
    "        data\n",
    "            training example\n",
    "\n",
    "        Returns\n",
    "        ---------\n",
    "        None, change matrix is filled in for weight updating\n",
    "        \"\"\"\n",
    "        # start at last layer\n",
    "        for layer in reversed(range(len(self.outputs))): \n",
    "            if layer == len(self.outputs) - 1: # for last layer, calculate loss using true values\n",
    "                for node in range(len(self.outputs[layer])):\n",
    "                    loss = (true_values[node] - self.outputs[layer][node])\n",
    "                    # fill in change matrix\n",
    "                    self.change[layer][node] = loss*sigmoid_derivative(self.outputs[layer][node])\n",
    "            else: # for all other layers\n",
    "                for node in range(len(self.outputs[layer])):\n",
    "                    loss = 0\n",
    "                    # sum weighted losses from previous layer\n",
    "                    for prev_layer_node in range(len(self.weights[layer + 1])):\n",
    "                        loss += self.weights[layer+1][prev_layer_node][node]*self.change[layer+1][prev_layer_node]\n",
    "                    # fill in change matrix\n",
    "                    self.change[layer][node] = loss*sigmoid_derivative(self.outputs[layer][node])\n",
    "         \n",
    "        \n",
    "        # Update weights\n",
    "        for layer in reversed(range(len(self.outputs))): \n",
    "            input = data[0] \n",
    "            if layer != 0: # the input to the first layer is the training example\n",
    "                input = [self.outputs[layer][node] for node in range(len(self.outputs[layer - 1]))]\n",
    "            for node in range(len(self.outputs[layer])):\n",
    "                for i in range(len(input)):\n",
    "                    self.weights[layer][node][i] += self.lr*self.change[layer][node]*input[i]\n",
    "                # update bias\n",
    "                self.weights[layer][node][-1] += self.lr*self.change[layer][node]\n",
    "        print(self.change)\n",
    "\n",
    "    def fit(self, training, validation, n_epochs):\n",
    "        \"\"\"\n",
    "        Trains the neural network and computes training loss.\n",
    "        After each epoch, computes the training and validation loss.\n",
    "        \n",
    "        Parameters\n",
    "        ---------\n",
    "        true_values\n",
    "            a list of true value(s) associated with the current\n",
    "            training example\n",
    "\n",
    "        Returns\n",
    "        ---------\n",
    "        Dataframe of \n",
    "        \"\"\"\n",
    "        #losses = pd.DataFrame(columns = ['Epoch', 'Train', 'Validation']) \n",
    "        #for epoch in range(n_epochs):\n",
    "            train_loss = 0\n",
    "            for row in training:\n",
    "                output = self.feedforward(row[0])\n",
    "                expected = row[-1] # Expected value should be last element of training row\n",
    "                # Sum loss of all output nodes\n",
    "                train_loss += sum([(expected[i]-output[i])**2 for i in range(len(expected))])\n",
    "                self.backprop(true_values=expected, data=row)\n",
    "            val_loss = 0\n",
    "            for val in validation:\n",
    "                output = self.predict(val[0])\n",
    "                expected = val[-1]\n",
    "                val_loss += sum([(expected[i]-output[i])**2 for i in range(len(expected))])\n",
    "            losses = losses.append({'Epoch' : epoch, 'Train' : train_loss/len(training), 'Validation': val_loss/len(validation)}, ignore_index=True)\n",
    "\n",
    "        return losses\n",
    "\n",
    "    def predict(self, data):\n",
    "        return self.feedforward(data)\n",
    "\n",
    "def activation(input, weights):\n",
    "    pass\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_seqs(pos_file, neg_file):\n",
    "    \"\"\"\n",
    "    Reads in positive and negative sequences from paths\n",
    "    into two lists, pos and neg. For negative sequences,\n",
    "    skips the lines starting with \">\"\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    pos_file\n",
    "        path to positive examples\n",
    "    neg_file\n",
    "        path to negative examples\n",
    "        \n",
    "    Returns\n",
    "    ---------\n",
    "    two lists, where each element is a sequence from the file\n",
    "    \"\"\"\n",
    "    with open(pos_file) as f:\n",
    "        pos = f.read().splitlines()\n",
    "    \n",
    "    neg = []\n",
    "    seq = ''\n",
    "    for line in open(neg_file):\n",
    "        if line.startswith(\">\"):\n",
    "            if seq != '':\n",
    "                neg.append(seq)\n",
    "                seq = ''\n",
    "        else:\n",
    "            seq += line.strip() \n",
    "    neg.append(seq)\n",
    "    return pos,neg\n",
    "\n",
    "def encode_seq(sequence):\n",
    "    \"\"\"\n",
    "    Performs one-hot encoding of a nucleotide sequence,\n",
    "    where each nucleotide is represented by a binary vector\n",
    "    of length 4, ie: [1, 0, 0, 0], where a 1 corresponds to\n",
    "    which nucleotide it is: [A, C, G, T]\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    sequence\n",
    "        the sequence string to encode\n",
    "        \n",
    "    Returns\n",
    "    ---------\n",
    "    A one-hot encoded sequence represented as a list of lists,\n",
    "    each with length 4\n",
    "    \"\"\"\n",
    "    encoded = []\n",
    "    for nuc in sequence:\n",
    "        if nuc == 'A':\n",
    "            encoded.append([1,0,0,0])\n",
    "        elif nuc == 'C':\n",
    "            encoded.append([0,1,0,0])\n",
    "        elif nuc == 'G':\n",
    "            encoded.append([0,0,1,0])\n",
    "        elif nuc == 'T':\n",
    "            encoded.append([0,0,0,1])\n",
    "    return encoded\n",
    "\n",
    "def train_val_split():\n",
    "    \"\"\"\n",
    "    Randomly split the positive and negative examples \n",
    "    into training and validation sets at an 80/20 ratio.\n",
    "    Since there are less pos examples, we are limited by\n",
    "    the \n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    sequence\n",
    "        the sequence string to encode\n",
    "        \n",
    "    Returns\n",
    "    ---------\n",
    "    A one-hot encoded sequence represented as a list of lists,\n",
    "    each with length 4\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_make_weights():\n",
    "    nn = NeuralNetwork(setup=[[8,3,\"sigmoid\",0],[3,8,\"sigmoid\",0]])\n",
    "    assert len(nn.weights) == 2\n",
    "    assert len(nn.weights[0]) == 3\n",
    "    assert len(nn.weights[1]) == 8\n",
    "    assert len(nn.weights[0][0]) == 9\n",
    "    assert len(nn.weights[1][0]) == 4\n",
    "\n",
    "def test_feedforward():\n",
    "    nn = NeuralNetwork([[2,1, \"sigmoid\",0], [1,2, \"sigmoid\",0]])\n",
    "    # a 2x1x2 network\n",
    "    out = nn.feedforward([1,1])\n",
    "    assert len(out) == 2\n",
    "    assert nn.outputs[1] == out\n",
    "    \n",
    "def test_encoder():\n",
    "    assert True\n",
    "\n",
    "def test_encoder_relu():\n",
    "    assert True\n",
    "\n",
    "def test_one_d_ouput():\n",
    "    assert True\n",
    "\n",
    "def test_read_train_seqs():\n",
    "    pos,neg = read_train_seqs(pos_file = \"./data/rap1-lieb-positives.txt\", neg_file = \"./data/yeast-upstream-1k-negative.fa\")\n",
    "    print(len(pos),len(neg))\n",
    "    assert len(neg) == 3164\n",
    "    assert len(pos) == 137\n",
    "    for i in range(len(pos)):\n",
    "        assert len(pos[i]) == 17\n",
    "\n",
    "def test_encode_seq():\n",
    "    seq = 'ACTG'\n",
    "    encoded = encode_seq(seq)\n",
    "    assert len(encoded) == 4\n",
    "    assert encoded == [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encode_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork([[8,3, \"sigmoid\",0], [3,8, \"sigmoid\",0]])\n",
    "# a 2x1x2 network\n",
    "nn.feedforward([1,0,0,0,0,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feedforward()\n",
    "test_make_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.backprop(true_values = [1,0,0,0,0,0,0,1], data = [[1,0,0,0,0,0,0,1], [1,0,0,0,0,0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.feedforward([1,0,0,0,0,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 8 bit binary vectors\n",
    "data = [list(np.random.randint(2, size=8)) for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = [[vector,vector] for vector in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into 80% train, 20% test\n",
    "train = new_data[0:800]\n",
    "test = new_data[800:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork([[8,3, \"sigmoid\",0], [3,8, \"sigmoid\",0]])\n",
    "nn.lr = 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = nn.fit(training = train, validation = test, n_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "for name in ['Train','Validation']:\n",
    "    ax.plot(df['Epoch'],df[name], label=name)\n",
    "\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"loss\")\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = [0,0,0,0,0,0,0,0]\n",
    "output = nn.predict([0,0,0,0,0,0,0,0]) \n",
    "sum([(expected[i]-output[i])**2 for i in range(len(expected))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = new_data[0:2]\n",
    "test = new_data[2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork([[8,3, \"sigmoid\",0], [3,8, \"sigmoid\",0]])\n",
    "nn.lr = 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = nn.fit(training = train, validation = test, n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
