{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import *\n",
    "class NeuralNetwork:\n",
    "    \"\"\"Class that creates a NN and includes methods to train and test\"\"\"\n",
    "    def __init__(self, setup=[[68,25,\"sigmoid\",0],[25,1,\"sigmoid\",0]],lr=.05,seed=1,error_rate=0,bias=1,iters=500,lamb=.00001,simple=0):\n",
    "        #Note - these paramaters are examples, not the required init function parameters\n",
    "        self._lr = lr\n",
    "        self._seed = seed\n",
    "        self._error_rate = error_rate\n",
    "        self._bias = bias\n",
    "        self._iters = iters\n",
    "        self._lamb = lamb\n",
    "        self._simple = simple\n",
    "        \n",
    "\n",
    "        # network is represented as a list of layers,\n",
    "        # where layers are a list of nodes, where nodes\n",
    "        # are a list of weights.\n",
    "        # weights = [ [[w1,w2...], [w1,w2...]] <- layer1\n",
    "        #             [[w1,w2...], [w1,w2...]] <- layer2\n",
    "        #           ]\n",
    "        weights = []\n",
    "        outputs = []\n",
    "        change = []\n",
    "        \n",
    "        # initialize the given number of layers with weights\n",
    "        for layer in setup:\n",
    "            weights.append(self.make_weights(n_inputs=layer[0],n_nodes=layer[1]))\n",
    "            outputs.append([0] * layer[1])\n",
    "            change.append([0] * layer[1])\n",
    "        \n",
    "        self._weights = weights\n",
    "        self._outputs = outputs\n",
    "        self._change = change\n",
    "        \n",
    "    @property\n",
    "    def lr(self):\n",
    "        return self._lr\n",
    "\n",
    "    @lr.setter\n",
    "    def lr(self, lr):\n",
    "        self._lr = lr\n",
    "\n",
    "    @property\n",
    "    def bias(self):\n",
    "        return self._bias\n",
    "\n",
    "    @bias.setter\n",
    "    def bias(self, bias):\n",
    "        self._bias = bias \n",
    "    \n",
    "    @property\n",
    "    def seed(self):\n",
    "        return self._seed\n",
    "\n",
    "    @seed.setter\n",
    "    def seed(self, seed):\n",
    "        self._seed = seed \n",
    "    \n",
    "    @property\n",
    "    def outputs(self):\n",
    "        return self._outputs\n",
    "\n",
    "    @outputs.setter\n",
    "    def outputs(self, outputs):\n",
    "        self._outputs = outputs \n",
    "        \n",
    "    @property\n",
    "    def change(self):\n",
    "        return self._change\n",
    "\n",
    "    @change.setter\n",
    "    def change(self, change):\n",
    "        self._change = change \n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        return self._weights\n",
    "\n",
    "    @weights.setter\n",
    "    def weights(self, weights):\n",
    "        self._weights = weights \n",
    "        \n",
    "        \n",
    "    def make_weights(self,n_inputs, n_nodes):\n",
    "        \"\"\"\n",
    "        Generates random weights for the network initialization\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        n_inputs\n",
    "            Number of input nodes to this layer\n",
    "        n_nodes\n",
    "            Number of nodes to generate weights for\n",
    "            \n",
    "        Returns\n",
    "        ---------\n",
    "        Layer with random weights initialized for each node\n",
    "        \"\"\"\n",
    "        seed(self.seed)\n",
    "        layer = []\n",
    "        \n",
    "        # Get n_inputs random numbers between 0 and 1 for each node\n",
    "        for i in range(n_nodes):\n",
    "            node_weights = [random() for j in range(n_inputs)]\n",
    "            node_weights.append(self.bias) # add bias at end\n",
    "            layer.append(node_weights)\n",
    "        \n",
    "        return layer\n",
    "\n",
    "    def feedforward(self, data):\n",
    "        \"\"\"\n",
    "        Takes in data and passes it through the NN\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        data\n",
    "            One datapoint\n",
    "            \n",
    "        Returns\n",
    "        ---------\n",
    "        The output(s) of the final layer in the network\n",
    "        \"\"\"\n",
    "        inputs = data\n",
    "        \n",
    "        # pass data through all layers\n",
    "        for layer in range(len(self.weights)):\n",
    "            next_inputs = []\n",
    "            for node in range(len(self.weights[layer])):\n",
    "                sum = 0\n",
    "                for i in range(len(inputs)): # multiply inputs by weights and add to sum\n",
    "                    sum += inputs[i]*self.weights[layer][node][i]\n",
    "                    \n",
    "                sum += self.weights[layer][node][-1] # add bias\n",
    "                output = sigmoid(sum) # Apply activation function\n",
    "                self.outputs[layer][node] = output\n",
    "                next_inputs.append(output)\n",
    "            inputs = next_inputs\n",
    "        \n",
    "        # inputs should now be the final layer output\n",
    "        return inputs\n",
    "    \n",
    "    def backprop(self, true_values, data):\n",
    "        \"\"\"\n",
    "        Calculates the loss and gradient for each output node.\n",
    "        Propagates the gradient through the network and records\n",
    "        the error for each node.\n",
    "        \n",
    "        Parameters\n",
    "        ---------\n",
    "        true_values\n",
    "            a list of true value(s) associated with the current\n",
    "            training example\n",
    "\n",
    "        Returns\n",
    "        ---------\n",
    "        None, change matrix is filled in for weight updating\n",
    "        \"\"\"\n",
    "        # start at last layer\n",
    "        for layer in reversed(range(len(self.outputs))): \n",
    "            if layer == len(self.outputs) - 1: # for last layer, calculate loss using true values\n",
    "                for node in range(len(self.outputs[layer])):\n",
    "                    loss = (true_values[node] - self.outputs[layer][node])\n",
    "                    # fill in change matrix\n",
    "                    self.change[layer][node] = loss*sigmoid_derivative(self.outputs[layer][node])\n",
    "            else: # for all other layers\n",
    "                for node in range(len(self.outputs[layer])):\n",
    "                    loss = 0\n",
    "                    # sum weighted losses from previous layer\n",
    "                    for prev_layer_node in range(len(self.weights[layer + 1])):\n",
    "                        loss += self.weights[layer+1][prev_layer_node][node]*self.change[layer+1][prev_layer_node]\n",
    "                    # fill in change matrix\n",
    "                    self.change[layer][node] = loss*sigmoid_derivative(self.outputs[layer][node])\n",
    "         \n",
    "        \n",
    "        # Update weights\n",
    "        for layer in reversed(range(len(self.outputs))): \n",
    "            input = data[-1] \n",
    "            if layer != 0: # the input to the first layer is the training example\n",
    "                input = [self.outputs[layer][node] for node in range(len(self.outputs[layer - 1]))]\n",
    "            for node in range(len(self.outputs[layer])):\n",
    "                for i in range(len(input)):\n",
    "                    self.weights[layer][node][i] += self.lr*self.change[layer][node]*input[i]\n",
    "                # update bias\n",
    "                self.weights[layer][node][-1] += self.lr*self.change[layer][node]\n",
    "                \n",
    "\n",
    "    def fit(self, training_data):\n",
    "        \"\"\"\n",
    "        Calculates the loss and gradient for each output node.\n",
    "        Propagates the gradient through the network and records\n",
    "        the error for each node.\n",
    "        \n",
    "        Parameters\n",
    "        ---------\n",
    "        true_values\n",
    "            a list of true value(s) associated with the current\n",
    "            training example\n",
    "\n",
    "        Returns\n",
    "        ---------\n",
    "        None, change matrix is filled in for weight updating\n",
    "        \"\"\"\n",
    "        for epoch in range(n_epoch):\n",
    "            sum_error = 0\n",
    "            for row in training_data:\n",
    "                output = feedforward(row)\n",
    "                # Expected value should be last element of training row\n",
    "                expected = row[-1]\n",
    "                # Sum loss of all output nodes\n",
    "                loss += sum([(expected[i]-output[i])**2 for i in range(len(expected))])\n",
    "                backprop(network, expected, row)\n",
    "            print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, loss))\n",
    "\n",
    "    def predict(self, data):\n",
    "        return feedforward(data)\n",
    "\n",
    "def activation(input, weights):\n",
    "    pass\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_make_weights():\n",
    "    nn = NeuralNetwork(setup=[[8,3,\"sigmoid\",0],[3,8,\"sigmoid\",0]])\n",
    "    assert len(nn.weights) == 2\n",
    "    assert len(nn.weights[0]) == 3\n",
    "    assert len(nn.weights[1]) == 8\n",
    "    assert len(nn.weights[0][0]) == 9\n",
    "    assert len(nn.weights[1][0]) == 4\n",
    "\n",
    "def test_feedforward():\n",
    "    nn = NeuralNetwork([[2,1, \"sigmoid\",0], [1,2, \"sigmoid\",0]])\n",
    "    # a 2x1x2 network\n",
    "    out = nn.feedforward([1,1])\n",
    "    assert len(out) == 2\n",
    "    assert nn.outputs[1] == out\n",
    "    \n",
    "def test_encoder():\n",
    "    assert True\n",
    "\n",
    "def test_encoder_relu():\n",
    "    assert True\n",
    "\n",
    "def test_one_d_ouput():\n",
    "    assert True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7536340857374849, 0.8512940040299428]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NeuralNetwork([[2,1, \"sigmoid\",0], [1,2, \"sigmoid\",0]])\n",
    "# a 2x1x2 network\n",
    "nn.feedforward([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feedforward()\n",
    "test_make_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.13436424411240122, 0.8474337369372327, 1]],\n",
       " [[0.13436424411240122, 1], [0.8474337369372327, 1]]]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.backprop(true_values = [1,1], data = [[1,1], [1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.1347128032791722, 0.8477822961040037, 1.000348559166771]],\n",
       " [[0.13638443114440094, 1.0026805940312835],\n",
       "  [0.8486085875694962, 1.001558913874117]]]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7552880993997311, 0.8519721417244803]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.feedforward([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.13436424411240122, 0.8474337369372327, 1]],\n",
       " [[0.13436424411240122, 1], [0.8474337369372327, 1]]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not numpy.float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-87cbdad567f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-87cbdad567f9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not numpy.float64"
     ]
    }
   ],
   "source": [
    "[nn.outputs[1][node] for node in nn.outputs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8788726974657645]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031178277482338014"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.change[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8474337369372327, 1]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.weights[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [[1,1], [1,1]]\n",
    "test[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
