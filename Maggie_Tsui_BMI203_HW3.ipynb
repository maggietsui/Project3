{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import *\n",
    "class NeuralNetwork:\n",
    "    \"\"\"Class that creates a NN and includes methods to train and test\"\"\"\n",
    "    def __init__(self, setup=[[68,25,\"sigmoid\",0],[25,1,\"sigmoid\",0]],lr=.05,seed=1,error_rate=0,bias=0.5,iters=500,lamb=.00001,simple=0):\n",
    "        #Note - these paramaters are examples, not the required init function parameters\n",
    "        self._lr = lr\n",
    "        self._seed = seed\n",
    "        self._error_rate = error_rate\n",
    "        self._bias = bias\n",
    "        self._iters = iters\n",
    "        self._lamb = lamb\n",
    "        self._simple = simple\n",
    "        \n",
    "\n",
    "        # network is represented as a list of layers,\n",
    "        # where layers are a list of nodes, where nodes\n",
    "        # are a list of weights.\n",
    "        # weights = [ [[w1,w2...], [w1,w2...]] <- layer1\n",
    "        #             [[w1,w2...], [w1,w2...]] <- layer2\n",
    "        #           ]\n",
    "        weights = []\n",
    "        outputs = []\n",
    "        change = []\n",
    "        \n",
    "        # initialize the given number of layers with weights\n",
    "        for layer in setup:\n",
    "            weights.append(self.make_weights(n_inputs=layer[0],n_nodes=layer[1]))\n",
    "            outputs.append([0] * layer[1])\n",
    "            change.append([0] * layer[1])\n",
    "        \n",
    "        self._weights = weights\n",
    "        self._outputs = outputs\n",
    "        self._change = change\n",
    "        \n",
    "    @property\n",
    "    def lr(self):\n",
    "        return self._lr\n",
    "\n",
    "    @lr.setter\n",
    "    def lr(self, lr):\n",
    "        self._lr = lr\n",
    "\n",
    "    @property\n",
    "    def bias(self):\n",
    "        return self._bias\n",
    "\n",
    "    @bias.setter\n",
    "    def bias(self, bias):\n",
    "        self._bias = bias \n",
    "    \n",
    "    @property\n",
    "    def seed(self):\n",
    "        return self._seed\n",
    "\n",
    "    @seed.setter\n",
    "    def seed(self, seed):\n",
    "        self._seed = seed \n",
    "    \n",
    "    @property\n",
    "    def outputs(self):\n",
    "        return self._outputs\n",
    "\n",
    "    @outputs.setter\n",
    "    def outputs(self, outputs):\n",
    "        self._outputs = outputs \n",
    "        \n",
    "    @property\n",
    "    def change(self):\n",
    "        return self._change\n",
    "\n",
    "    @change.setter\n",
    "    def change(self, change):\n",
    "        self._change = change \n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        return self._weights\n",
    "\n",
    "    @weights.setter\n",
    "    def weights(self, weights):\n",
    "        self._weights = weights \n",
    "        \n",
    "        \n",
    "    def make_weights(self,n_inputs, n_nodes):\n",
    "        \"\"\"\n",
    "        Generates random weights for the network initialization\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        n_inputs\n",
    "            Number of input nodes to this layer\n",
    "        n_nodes\n",
    "            Number of nodes to generate weights for\n",
    "            \n",
    "        Returns\n",
    "        ---------\n",
    "        Layer with random weights initialized for each node\n",
    "        \"\"\"\n",
    "        #seed(self.seed)\n",
    "        layer = []\n",
    "        \n",
    "        # Get n_inputs random float between -1 and 1 for each node\n",
    "        for i in range(n_nodes):\n",
    "            node_weights = [uniform(-1, 1) for j in range(n_inputs)]\n",
    "            node_weights.append(self.bias) # add bias at end\n",
    "            layer.append(node_weights)\n",
    "        \n",
    "        return layer\n",
    "\n",
    "    def feedforward(self, data):\n",
    "        \"\"\"\n",
    "        Takes in data and passes it through the NN\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        data\n",
    "            One datapoint\n",
    "            \n",
    "        Returns\n",
    "        ---------\n",
    "        The output(s) of the final layer in the network\n",
    "        \"\"\"\n",
    "        inputs = data\n",
    "        \n",
    "        # pass data through all layers\n",
    "        for layer in range(len(self.weights)):\n",
    "            next_inputs = []\n",
    "            for node in range(len(self.weights[layer])):\n",
    "                sum = 0\n",
    "                for i in range(len(inputs)): # multiply inputs by weights and add to sum\n",
    "                    sum += inputs[i]*self.weights[layer][node][i]\n",
    "                    \n",
    "                sum += self.weights[layer][node][-1] # add bias\n",
    "                output = sigmoid(sum) # Apply activation function\n",
    "                self.outputs[layer][node] = output\n",
    "                next_inputs.append(output)\n",
    "            inputs = next_inputs\n",
    "        # inputs should now be the final layer output\n",
    "        return inputs\n",
    "    \n",
    "    def backprop(self, true_values, data):\n",
    "        \"\"\"\n",
    "        Calculates the loss and gradient for each output node.\n",
    "        Propagates the gradient through the network and records\n",
    "        the error for each node.\n",
    "        \n",
    "        Parameters\n",
    "        ---------\n",
    "        true_values\n",
    "            true classification of example\n",
    "        data\n",
    "            training example\n",
    "\n",
    "        Returns\n",
    "        ---------\n",
    "        None, change matrix is filled in for weight updating\n",
    "        \"\"\"\n",
    "        # start at last layer\n",
    "        for layer in reversed(range(len(self.outputs))): \n",
    "            if layer == len(self.outputs) - 1: # for last layer, calculate loss using true values\n",
    "                for node in range(len(self.outputs[layer])):\n",
    "                    loss = (true_values[node] - self.outputs[layer][node])\n",
    "                    # fill in change matrix\n",
    "                    self.change[layer][node] = loss*sigmoid_derivative(self.outputs[layer][node])\n",
    "            else: # for all other layers\n",
    "                for node in range(len(self.outputs[layer])):\n",
    "                    loss = 0\n",
    "                    # sum weighted losses from previous layer\n",
    "                    for prev_layer_node in range(len(self.weights[layer + 1])):\n",
    "                        loss += self.weights[layer+1][prev_layer_node][node]*self.change[layer+1][prev_layer_node]\n",
    "                    # fill in change matrix\n",
    "                    self.change[layer][node] = loss*sigmoid_derivative(self.outputs[layer][node])\n",
    "         \n",
    "        \n",
    "        # Update weights\n",
    "        for layer in reversed(range(len(self.outputs))): \n",
    "            input = data[0] # the input to the first layer is the training example\n",
    "            if layer != 0: # the input to rest of layers is output of prev layer\n",
    "                input = [self.outputs[layer-1][node] for node in range(len(self.outputs[layer - 1]))]\n",
    "            for node in range(len(self.outputs[layer])):\n",
    "                for i in range(len(input)):\n",
    "                    self.weights[layer][node][i] += self.lr*self.change[layer][node]*input[i]\n",
    "                # update bias\n",
    "                self.weights[layer][node][-1] += self.lr*self.change[layer][node]\n",
    "\n",
    "\n",
    "    def fit(self, training):\n",
    "        \"\"\"\n",
    "        Trains the neural network and computes training loss.\n",
    "        After each epoch, computes the training and validation loss.\n",
    "        \n",
    "        Parameters\n",
    "        ---------\n",
    "        true_values\n",
    "            a list of true value(s) associated with the current\n",
    "            training example\n",
    "\n",
    "        Returns\n",
    "        ---------\n",
    "        Dataframe of \n",
    "        \"\"\"\n",
    "        train_loss = 0\n",
    "        for row in training:\n",
    "            output = self.feedforward(row[0])\n",
    "            expected = row[-1] # Expected value should be last element of training row\n",
    "            # Sum loss of all output nodes\n",
    "            train_loss += sum([(expected[i]-output[i])**2 for i in range(len(expected))])\n",
    "            self.backprop(true_values=expected, data=row)\n",
    "        return train_loss/len(training)\n",
    "        \n",
    "    def predict(self, data):\n",
    "        return self.feedforward(data)\n",
    "\n",
    "def activation(input, weights):\n",
    "    pass\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_seqs(pos_file, neg_file):\n",
    "    \"\"\"\n",
    "    Reads in positive and negative sequences from paths\n",
    "    into two lists, pos and neg. For negative sequences,\n",
    "    skips the lines starting with \">\"\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    pos_file\n",
    "        path to positive examples\n",
    "    neg_file\n",
    "        path to negative examples\n",
    "        \n",
    "    Returns\n",
    "    ---------\n",
    "    two lists, where each element is a sequence from the file\n",
    "    \"\"\"\n",
    "    with open(pos_file) as f:\n",
    "        pos = f.read().splitlines()\n",
    "    \n",
    "    neg = []\n",
    "    seq = ''\n",
    "    for line in open(neg_file):\n",
    "        if line.startswith(\">\"):\n",
    "            if seq != '':\n",
    "                neg.append(seq)\n",
    "                seq = ''\n",
    "        else:\n",
    "            seq += line.strip() \n",
    "    neg.append(seq)\n",
    "    return pos,neg\n",
    "\n",
    "def encode_seq(sequence):\n",
    "    \"\"\"\n",
    "    Performs one-hot encoding of a nucleotide sequence,\n",
    "    where each nucleotide is represented by a binary vector\n",
    "    of length 4, ie: [1, 0, 0, 0], where a 1 corresponds to\n",
    "    which nucleotide it is: [A, C, G, T]\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    sequence\n",
    "        the sequence string to encode\n",
    "        \n",
    "    Returns\n",
    "    ---------\n",
    "    A one-hot encoded sequence represented as a list of lists,\n",
    "    each with length 4\n",
    "    \"\"\"\n",
    "    encoded = []\n",
    "    for nuc in sequence:\n",
    "        if nuc == 'A':\n",
    "            encoded+=[1,0,0,0]\n",
    "        elif nuc == 'C':\n",
    "            encoded+=[0,1,0,0]\n",
    "        elif nuc == 'G':\n",
    "            encoded+=[0,0,1,0]\n",
    "        elif nuc == 'T':\n",
    "            encoded+=[0,0,0,1]\n",
    "    return encoded\n",
    "\n",
    "def train_val_split():\n",
    "    \"\"\"\n",
    "    Randomly split the positive and negative examples \n",
    "    into training and validation sets at an 80/20 ratio.\n",
    "    Since there are less pos examples, we are limited by\n",
    "    the \n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    sequence\n",
    "        the sequence string to encode\n",
    "        \n",
    "    Returns\n",
    "    ---------\n",
    "    A one-hot encoded sequence represented as a list of lists,\n",
    "    each with length 4\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_make_weights():\n",
    "    nn = NeuralNetwork(setup=[[8,3,\"sigmoid\",0],[3,8,\"sigmoid\",0]])\n",
    "    assert len(nn.weights) == 2\n",
    "    assert len(nn.weights[0]) == 3\n",
    "    assert len(nn.weights[1]) == 8\n",
    "    assert len(nn.weights[0][0]) == 9\n",
    "    assert len(nn.weights[1][0]) == 4\n",
    "\n",
    "def test_feedforward():\n",
    "    nn = NeuralNetwork([[2,1, \"sigmoid\",0], [1,2, \"sigmoid\",0]])\n",
    "    # a 2x1x2 network\n",
    "    out = nn.feedforward([1,1])\n",
    "    assert len(out) == 2\n",
    "    assert nn.outputs[1] == out\n",
    "    \n",
    "def test_encoder():\n",
    "    assert True\n",
    "\n",
    "def test_encoder_relu():\n",
    "    assert True\n",
    "\n",
    "def test_one_d_ouput():\n",
    "    assert True\n",
    "\n",
    "def test_read_train_seqs():\n",
    "    pos,neg = read_train_seqs(pos_file = \"./data/rap1-lieb-positives.txt\", neg_file = \"./data/yeast-upstream-1k-negative.fa\")\n",
    "    print(len(pos),len(neg))\n",
    "    assert len(neg) == 3164\n",
    "    assert len(pos) == 137\n",
    "    for i in range(len(pos)):\n",
    "        assert len(pos[i]) == 17\n",
    "\n",
    "def test_encode_seq():\n",
    "    seq = 'ACTG'\n",
    "    encoded = encode_seq(seq)\n",
    "    assert len(encoded) == 16\n",
    "    assert encoded == [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encode_seq()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 8 bit binary vectors\n",
    "identity = list(np.identity(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [[list(i),list(i)] for i in identity]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork([[8,3, \"sigmoid\",0], [3,8, \"sigmoid\",0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(columns = ['Epoch', 'Train']) \n",
    "nn.lr = 0.3\n",
    "for epoch in range(2000):\n",
    "    if epoch == 5000:\n",
    "        nn.lr = 0.05\n",
    "    loss = nn.fit(train)\n",
    "    losses = losses.append({'Epoch' : epoch, 'Train' : loss}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "for name in ['Train']:\n",
    "    ax.plot(losses['Epoch'],losses[name], label=name)\n",
    "\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"loss\")\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.predict([0,0,1,0,0,0,0,0]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test NN for TF binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAATCTTCACCACCCAA',\n",
       " 'AGTAAATAACAGATAAT',\n",
       " 'CATTGTAAAGGAAAACC',\n",
       " 'AAAATAATAGGTGTAAA']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives, full_negs = read_train_seqs(pos_file=\"./data/rap1-lieb-positives.txt\", neg_file=\"./data/yeast-upstream-1k-negative.fa\")\n",
    "\n",
    "# just take the last 17 bp of all of the negatives\n",
    "negatives = [seq[len(seq)-17:len(seq)] for seq in full_negs]\n",
    "negatives[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_enc = [[encode_seq(seq),[1]] for seq in positives]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_enc = [[encode_seq(seq),[0]] for seq in negatives]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put some examples in a validation set. \n",
    "# 80/20 split for positives: Since there are only 137 positives, let's save 27 positives.\n",
    "# Let's just save 64 negs for validation.\n",
    "\n",
    "pos_test_len = 27\n",
    "pos_test_idx = sample(range(len(pos_enc)), pos_test_len)\n",
    "neg_test_len = 64\n",
    "neg_test_idx = sample(range(len(neg_enc)), neg_test_len)\n",
    "\n",
    "pos_test = [pos_enc[idx] for idx in pos_test_idx]\n",
    "neg_test = [neg_enc[idx] for idx in neg_test_idx]\n",
    "\n",
    "pos_train = [pos_enc[idx] for idx in range(len(pos_enc)) if idx not in pos_test_idx]\n",
    "neg_train = [neg_enc[idx] for idx in range(len(neg_enc)) if idx not in neg_test_idx]\n",
    "\n",
    "validation = pos_test + neg_test\n",
    "shuffle(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "\n",
    "# make two queues\n",
    "pos_queue = queue.Queue(maxsize=0) \n",
    "  \n",
    "for i in range(len(pos_train)):\n",
    "    pos_queue.put(pos_train[i])\n",
    "\n",
    "neg_queue = queue.Queue(maxsize=0) \n",
    "  \n",
    "for i in range(len(neg_train)):\n",
    "    neg_queue.put(neg_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_batch_size = 50\n",
    "neg_batch_size = 155\n",
    "n_epochs = 5\n",
    "losses = pd.DataFrame(columns = ['Epoch', 'Train', 'Validation']) \n",
    "\n",
    "nn = NeuralNetwork([[68,25, \"sigmoid\",0], [25,1, \"sigmoid\",0]])\n",
    "nn.lr = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    batch_losses = []\n",
    "    # run through all neg examples while upsampling pos examples\n",
    "    while neg_queue.empty() == False:\n",
    "        # get a new batch of positive and neg examples\n",
    "        neg_batch = [neg_queue.get() for i in range(neg_batch_size)]\n",
    "        pos_batch = []\n",
    "        for i in range(pos_batch_size):\n",
    "            if pos_queue.empty(): # replenesh pos samples when necessary\n",
    "                for i in range(len(pos_train)):\n",
    "                    pos_queue.put(pos_train[i])\n",
    "            pos_batch.append(pos_queue.get())\n",
    "        \n",
    "        train = neg_batch + pos_batch\n",
    "        shuffle(train)\n",
    "        \n",
    "        batch_losses.append(nn.fit(train))\n",
    "        \n",
    "    # Average over the batch losses    \n",
    "    train_loss = sum(batch_losses)/len(batch_losses)\n",
    "    \n",
    "    val_loss = 0\n",
    "    for val in validation:\n",
    "        output = nn.predict(val[0])\n",
    "        expected = val[-1]\n",
    "        val_loss += sum([(expected[i]-output[i])**2 for i in range(len(expected))])\n",
    "    losses = losses.append({'Epoch' : epoch, 'Train' : train_loss,\n",
    "                            'Validation': val_loss/len(validation)}, ignore_index=True)\n",
    "    \n",
    "    # shuffle negative examples and add to queue\n",
    "    shuffle(neg_train)\n",
    "    for i in range(len(neg_train)):\n",
    "        neg_queue.put(neg_train[i])\n",
    "        \n",
    "    shuffle(pos_train)\n",
    "    pos_queue.queue.clear()\n",
    "    for i in range(len(pos_train)):\n",
    "        pos_queue.put(pos_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00018105462032776018]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.predict(validation[10][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f85fa11ddc0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "for name in ['Train', 'Validation']:\n",
    "    ax.plot(losses['Epoch'],losses[name], label=name)\n",
    "\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"loss\")\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0],\n",
       " [0]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = queue.Queue(maxsize=0) \n",
    "  \n",
    "positives.put([[1,0,0,0,1],1])\n",
    "positives.put([[1,0,0,0,1],0])\n",
    "positives.put([[1,0,0,1,1],1])\n",
    "\n",
    "print(positives.get(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_queue.empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives.empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq ='ACATCCGTGCACCTCCG'\n",
    "seq[len(seq)-17:len(seq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.identity(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
