{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import *\n",
    "class NeuralNetwork:\n",
    "    \"\"\"Class that creates a NN and includes methods to train and test\"\"\"\n",
    "    def __init__(self, setup=[[68,25,\"sigmoid\",0],[25,1,\"sigmoid\",0]],lr=.05,seed=1,error_rate=0,bias=0.5,iters=500,lamb=.00001,simple=0):\n",
    "        #Note - these paramaters are examples, not the required init function parameters\n",
    "        self._lr = lr\n",
    "        self._seed = seed\n",
    "        self._error_rate = error_rate\n",
    "        self._bias = bias\n",
    "        self._iters = iters\n",
    "        self._lamb = lamb\n",
    "        self._simple = simple\n",
    "        \n",
    "\n",
    "        # network is represented as a list of layers,\n",
    "        # where layers are a list of nodes, where nodes\n",
    "        # are a list of weights.\n",
    "        # weights = [ [[w1,w2...], [w1,w2...]] <- layer1\n",
    "        #             [[w1,w2...], [w1,w2...]] <- layer2\n",
    "        #           ]\n",
    "        weights = []\n",
    "        outputs = []\n",
    "        change = []\n",
    "        \n",
    "        # initialize the given number of layers with weights\n",
    "        for layer in setup:\n",
    "            weights.append(self.make_weights(n_inputs=layer[0],n_nodes=layer[1]))\n",
    "            outputs.append([0] * layer[1])\n",
    "            change.append([0] * layer[1])\n",
    "        \n",
    "        self._weights = weights\n",
    "        self._outputs = outputs\n",
    "        self._change = change\n",
    "        \n",
    "    @property\n",
    "    def lr(self):\n",
    "        return self._lr\n",
    "\n",
    "    @lr.setter\n",
    "    def lr(self, lr):\n",
    "        self._lr = lr\n",
    "\n",
    "    @property\n",
    "    def bias(self):\n",
    "        return self._bias\n",
    "\n",
    "    @bias.setter\n",
    "    def bias(self, bias):\n",
    "        self._bias = bias \n",
    "    \n",
    "    @property\n",
    "    def seed(self):\n",
    "        return self._seed\n",
    "\n",
    "    @seed.setter\n",
    "    def seed(self, seed):\n",
    "        self._seed = seed \n",
    "    \n",
    "    @property\n",
    "    def outputs(self):\n",
    "        return self._outputs\n",
    "\n",
    "    @outputs.setter\n",
    "    def outputs(self, outputs):\n",
    "        self._outputs = outputs \n",
    "        \n",
    "    @property\n",
    "    def change(self):\n",
    "        return self._change\n",
    "\n",
    "    @change.setter\n",
    "    def change(self, change):\n",
    "        self._change = change \n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        return self._weights\n",
    "\n",
    "    @weights.setter\n",
    "    def weights(self, weights):\n",
    "        self._weights = weights \n",
    "        \n",
    "        \n",
    "    def make_weights(self,n_inputs, n_nodes):\n",
    "        \"\"\"\n",
    "        Generates random weights for the network initialization\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        n_inputs\n",
    "            Number of input nodes to this layer\n",
    "        n_nodes\n",
    "            Number of nodes to generate weights for\n",
    "            \n",
    "        Returns\n",
    "        ---------\n",
    "        Layer with random weights initialized for each node\n",
    "        \"\"\"\n",
    "        #seed(self.seed)\n",
    "        layer = []\n",
    "        \n",
    "        # Get n_inputs random float between -1 and 1 for each node\n",
    "        for i in range(n_nodes):\n",
    "            node_weights = [uniform(-1, 1) for j in range(n_inputs)]\n",
    "            node_weights.append(self.bias) # add bias at end\n",
    "            layer.append(node_weights)\n",
    "        \n",
    "        return layer\n",
    "\n",
    "    def feedforward(self, data):\n",
    "        \"\"\"\n",
    "        Takes in data and passes it through the NN\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        data\n",
    "            One datapoint\n",
    "            \n",
    "        Returns\n",
    "        ---------\n",
    "        The output(s) of the final layer in the network\n",
    "        \"\"\"\n",
    "        inputs = data\n",
    "        \n",
    "        # pass data through all layers\n",
    "        for layer in range(len(self.weights)):\n",
    "            next_inputs = []\n",
    "            for node in range(len(self.weights[layer])):\n",
    "                sum = 0\n",
    "                for i in range(len(inputs)): # multiply inputs by weights and add to sum\n",
    "                    sum += inputs[i]*self.weights[layer][node][i]\n",
    "                    \n",
    "                sum += self.weights[layer][node][-1] # add bias\n",
    "                output = sigmoid(sum) # Apply activation function\n",
    "                self.outputs[layer][node] = output\n",
    "                next_inputs.append(output)\n",
    "            inputs = next_inputs\n",
    "        # inputs should now be the final layer output\n",
    "        return inputs\n",
    "    \n",
    "    def backprop(self, true_values, data):\n",
    "        \"\"\"\n",
    "        Calculates the loss and gradient for each output node.\n",
    "        Propagates the gradient through the network and records\n",
    "        the error for each node.\n",
    "        \n",
    "        Parameters\n",
    "        ---------\n",
    "        true_values\n",
    "            true classification of example\n",
    "        data\n",
    "            training example\n",
    "\n",
    "        Returns\n",
    "        ---------\n",
    "        None, change matrix is filled in for weight updating\n",
    "        \"\"\"\n",
    "        # start at last layer\n",
    "        for layer in reversed(range(len(self.outputs))): \n",
    "            if layer == len(self.outputs) - 1: # for last layer, calculate loss using true values\n",
    "                for node in range(len(self.outputs[layer])):\n",
    "                    loss = (true_values[node] - self.outputs[layer][node])\n",
    "                    # fill in change matrix\n",
    "                    self.change[layer][node] = loss*sigmoid_derivative(self.outputs[layer][node])\n",
    "            else: # for all other layers\n",
    "                for node in range(len(self.outputs[layer])):\n",
    "                    loss = 0\n",
    "                    # sum weighted losses from previous layer\n",
    "                    for prev_layer_node in range(len(self.weights[layer + 1])):\n",
    "                        loss += self.weights[layer+1][prev_layer_node][node]*self.change[layer+1][prev_layer_node]\n",
    "                    # fill in change matrix\n",
    "                    self.change[layer][node] = loss*sigmoid_derivative(self.outputs[layer][node])\n",
    "         \n",
    "        \n",
    "        # Update weights\n",
    "        for layer in reversed(range(len(self.outputs))): \n",
    "            input = data[0] # the input to the first layer is the training example\n",
    "            if layer != 0: # the input to rest of layers is output of prev layer\n",
    "                input = [self.outputs[layer-1][node] for node in range(len(self.outputs[layer - 1]))]\n",
    "            for node in range(len(self.outputs[layer])):\n",
    "                for i in range(len(input)):\n",
    "                    self.weights[layer][node][i] += self.lr*self.change[layer][node]*input[i]\n",
    "                # update bias\n",
    "                self.weights[layer][node][-1] += self.lr*self.change[layer][node]\n",
    "\n",
    "\n",
    "    def fit(self, training):\n",
    "        \"\"\"\n",
    "        Trains the neural network and computes training loss.\n",
    "        After each epoch, computes the training and validation loss.\n",
    "        \n",
    "        Parameters\n",
    "        ---------\n",
    "        true_values\n",
    "            a list of true value(s) associated with the current\n",
    "            training example\n",
    "\n",
    "        Returns\n",
    "        ---------\n",
    "        Dataframe of \n",
    "        \"\"\"\n",
    "        train_loss = 0\n",
    "        for row in training:\n",
    "            output = self.feedforward(row[0])\n",
    "            expected = row[-1] # Expected value should be last element of training row\n",
    "            # Sum loss of all output nodes\n",
    "            train_loss += sum([(expected[i]-output[i])**2 for i in range(len(expected))])\n",
    "            self.backprop(true_values=expected, data=row)\n",
    "        return train_loss/len(training)\n",
    "        \n",
    "    def predict(self, data):\n",
    "        return self.feedforward(data)\n",
    "    \n",
    "\n",
    "def activation(input, weights):\n",
    "    pass\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_seqs(pos_file, neg_file):\n",
    "    \"\"\"\n",
    "    Reads in positive and negative sequences from paths\n",
    "    into two lists, pos and neg. For negative sequences,\n",
    "    skips the lines starting with \">\"\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    pos_file\n",
    "        path to positive examples\n",
    "    neg_file\n",
    "        path to negative examples\n",
    "        \n",
    "    Returns\n",
    "    ---------\n",
    "    two lists, where each element is a sequence from the file\n",
    "    \"\"\"\n",
    "    with open(pos_file) as f:\n",
    "        pos = f.read().splitlines()\n",
    "    \n",
    "    neg = []\n",
    "    seq = ''\n",
    "    for line in open(neg_file):\n",
    "        if line.startswith(\">\"):\n",
    "            if seq != '':\n",
    "                neg.append(seq)\n",
    "                seq = ''\n",
    "        else:\n",
    "            seq += line.strip() \n",
    "    neg.append(seq)\n",
    "    return pos,neg\n",
    "\n",
    "def encode_seq(sequence):\n",
    "    \"\"\"\n",
    "    Performs one-hot encoding of a nucleotide sequence,\n",
    "    where each nucleotide is represented by a binary vector\n",
    "    of length 4, ie: [1, 0, 0, 0], where a 1 corresponds to\n",
    "    which nucleotide it is: [A, C, G, T]\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    sequence\n",
    "        the sequence string to encode\n",
    "        \n",
    "    Returns\n",
    "    ---------\n",
    "    A one-hot encoded sequence represented as a list of lists,\n",
    "    each with length 4\n",
    "    \"\"\"\n",
    "    encoded = []\n",
    "    for nuc in sequence:\n",
    "        if nuc == 'A':\n",
    "            encoded+=[1,0,0,0]\n",
    "        elif nuc == 'C':\n",
    "            encoded+=[0,1,0,0]\n",
    "        elif nuc == 'G':\n",
    "            encoded+=[0,0,1,0]\n",
    "        elif nuc == 'T':\n",
    "            encoded+=[0,0,0,1]\n",
    "    return encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(pos_batch_size, neg_batch_size, n_epochs, nn):\n",
    "    losses = pd.DataFrame(columns = ['Epoch', 'Train', 'Validation']) \n",
    "    for epoch in range(n_epochs):\n",
    "        batch_losses = []\n",
    "        # run through all neg examples while upsampling pos examples\n",
    "        while neg_queue.empty() == False:\n",
    "            # get a new batch of positive and neg examples\n",
    "            neg_batch = [neg_queue.get() for i in range(neg_batch_size)]\n",
    "            pos_batch = []\n",
    "            for i in range(pos_batch_size):\n",
    "                if pos_queue.empty(): # replenesh pos samples when necessary\n",
    "                    for i in range(len(pos_train)):\n",
    "                        pos_queue.put(pos_train[i])\n",
    "                pos_batch.append(pos_queue.get())\n",
    "\n",
    "            train = neg_batch + pos_batch\n",
    "            shuffle(train)\n",
    "\n",
    "            batch_losses.append(nn.fit(train))\n",
    "\n",
    "        # Average over the batch losses    \n",
    "        train_loss = sum(batch_losses)/len(batch_losses)\n",
    "\n",
    "        val_loss = 0\n",
    "        for val in validation:\n",
    "            output = nn.predict(val[0])\n",
    "            expected = val[-1]\n",
    "            val_loss += sum([(expected[i]-output[i])**2 for i in range(len(expected))])\n",
    "        losses = losses.append({'Epoch' : epoch, 'Train' : train_loss,\n",
    "                                'Validation': val_loss/len(validation)}, ignore_index=True)\n",
    "\n",
    "        # shuffle negative examples and add to queue\n",
    "        shuffle(neg_train)\n",
    "        for i in range(len(neg_train)):\n",
    "            neg_queue.put(neg_train[i])\n",
    "\n",
    "        shuffle(pos_train)\n",
    "        pos_queue.queue.clear()\n",
    "        for i in range(len(pos_train)):\n",
    "            pos_queue.put(pos_train[i])\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_make_weights():\n",
    "    nn = NeuralNetwork(setup=[[8,3,\"sigmoid\",0],[3,8,\"sigmoid\",0]])\n",
    "    assert len(nn.weights) == 2\n",
    "    assert len(nn.weights[0]) == 3\n",
    "    assert len(nn.weights[1]) == 8\n",
    "    assert len(nn.weights[0][0]) == 9\n",
    "    assert len(nn.weights[1][0]) == 4\n",
    "\n",
    "def test_feedforward():\n",
    "    nn = NeuralNetwork([[2,1, \"sigmoid\",0], [1,2, \"sigmoid\",0]])\n",
    "    # a 2x1x2 network\n",
    "    out = nn.feedforward([1,1])\n",
    "    assert len(out) == 2\n",
    "    assert nn.outputs[1] == out\n",
    "    \n",
    "def test_encoder():\n",
    "    assert True\n",
    "\n",
    "def test_encoder_relu():\n",
    "    assert True\n",
    "\n",
    "def test_one_d_ouput():\n",
    "    assert True\n",
    "\n",
    "def test_read_train_seqs():\n",
    "    pos,neg = read_train_seqs(pos_file = \"./data/rap1-lieb-positives.txt\", neg_file = \"./data/yeast-upstream-1k-negative.fa\")\n",
    "    print(len(pos),len(neg))\n",
    "    assert len(neg) == 3164\n",
    "    assert len(pos) == 137\n",
    "    for i in range(len(pos)):\n",
    "        assert len(pos[i]) == 17\n",
    "\n",
    "def test_encode_seq():\n",
    "    seq = 'ACTG'\n",
    "    encoded = encode_seq(seq)\n",
    "    assert len(encoded) == 16\n",
    "    assert encoded == [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encode_seq()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 8 bit binary vectors\n",
    "identity = list(np.identity(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [[list(i),list(i)] for i in identity]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork([[8,3, \"sigmoid\",0], [3,8, \"sigmoid\",0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(columns = ['Epoch', 'Train']) \n",
    "nn.lr = 0.3\n",
    "for epoch in range(2000):\n",
    "    if epoch == 5000:\n",
    "        nn.lr = 0.05\n",
    "    loss = nn.fit(train)\n",
    "    losses = losses.append({'Epoch' : epoch, 'Train' : loss}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "for name in ['Train']:\n",
    "    ax.plot(losses['Epoch'],losses[name], label=name)\n",
    "\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"loss\")\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.predict([0,0,1,0,0,0,0,0]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test NN for TF binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAATCTTCACCACCCAA',\n",
       " 'AGTAAATAACAGATAAT',\n",
       " 'CATTGTAAAGGAAAACC',\n",
       " 'AAAATAATAGGTGTAAA']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives, full_negs = read_train_seqs(pos_file=\"./data/rap1-lieb-positives.txt\", neg_file=\"./data/yeast-upstream-1k-negative.fa\")\n",
    "\n",
    "# just take the last 17 bp of all of the negatives\n",
    "negatives = [seq[len(seq)-17:len(seq)] for seq in full_negs]\n",
    "negatives[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_enc = [[encode_seq(seq),[1]] for seq in positives]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_enc = [[encode_seq(seq),[0]] for seq in negatives]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put some examples in a validation set. \n",
    "# 80/20 split for positives: Since there are only 137 positives, let's save 27 positives.\n",
    "# Let's just save 64 negs for validation.\n",
    "\n",
    "pos_test_len = 27\n",
    "pos_test_idx = sample(range(len(pos_enc)), pos_test_len)\n",
    "neg_test_len = 64\n",
    "neg_test_idx = sample(range(len(neg_enc)), neg_test_len)\n",
    "\n",
    "pos_test = [pos_enc[idx] for idx in pos_test_idx]\n",
    "neg_test = [neg_enc[idx] for idx in neg_test_idx]\n",
    "\n",
    "pos_train = [pos_enc[idx] for idx in range(len(pos_enc)) if idx not in pos_test_idx]\n",
    "neg_train = [neg_enc[idx] for idx in range(len(neg_enc)) if idx not in neg_test_idx]\n",
    "\n",
    "validation = pos_test + neg_test\n",
    "shuffle(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "\n",
    "# make two queues\n",
    "pos_queue = queue.Queue(maxsize=0) \n",
    "  \n",
    "for i in range(len(pos_train)):\n",
    "    pos_queue.put(pos_train[i])\n",
    "\n",
    "neg_queue = queue.Queue(maxsize=0) \n",
    "  \n",
    "for i in range(len(neg_train)):\n",
    "    neg_queue.put(neg_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork([[68,25, \"sigmoid\",0], [25,1, \"sigmoid\",0]])\n",
    "nn.lr = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = training(pos_batch_size = 50,neg_batch_size = 155, n_epochs = 50, nn = nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f85fc5102e0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "for name in ['Train', 'Validation']:\n",
    "    ax.plot(losses['Epoch'],losses[name], label=name)\n",
    "\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"loss\")\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.687661466133474e-07]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.predict(validation[10][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a 5-fold cross validation\n",
    "# There are 3301 total examples, 3164 neg and 137 pos\n",
    "# Need to class balance folds, so just split both pos and neg into 5 folds, then combine to form a fold\n",
    "# (last fold contains the rest if uneven)\n",
    "# Need to class balance the folds. \n",
    "k = 5\n",
    "# n examples to include in each fold\n",
    "n_pos_folds = len(pos_enc)/k\n",
    "n_neg_folds = len(neg_enc)/k\n",
    "\n",
    "for i in range(k):\n",
    "    if i == k: # for the last fold, use all remaining data\n",
    "        pos_val = pos_enc[i*n_pos_folds:]\n",
    "        neg_val = neg_enc[i*n_neg_folds:]\n",
    "        validation = pos_val + neg_val\n",
    "        shuffle(validation)\n",
    "    else:\n",
    "        pos_val = pos_enc[i*n_pos_folds:i*n_pos_folds+n_pos_folds]\n",
    "        neg_val = neg_enc[i*n_neg_folds:i*n_neg_folds+n_neg_folds]\n",
    "        validation = pos_val + neg_val\n",
    "        shuffle(validation)\n",
    "    # train is just all examples minus the fold\n",
    "    pos_train = [:i*n_pos_folds]\n",
    "    neg_train = [:i*n_neg_folds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [1,2,3]\n",
    "l[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with all pos and neg examples\n",
    "# for each fold\n",
    "    # put fold in in test, the rest in train\n",
    "    # run training\n",
    "    # actual = []\n",
    "    # actual.append(test set )\n",
    "    # output pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fpr, tpr, and auc for each model\n",
    "result_table = pd.DataFrame(columns=['score_mat', 'fpr','tpr','auc'])\n",
    "\n",
    "i = 1\n",
    "for pred,actual in folds.items():  \n",
    "    fpr, tpr, _ = roc_curve(actual,  pred)\n",
    "    auc = roc_auc_score(actual, pred)\n",
    "    \n",
    "    result_table = result_table.append({'k': i,\n",
    "                                        'fpr':fpr, \n",
    "                                        'tpr':tpr, \n",
    "                                        'auc':auc}, ignore_index=True)\n",
    "    i+=1\n",
    "result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC \n",
    "fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "for i in result_table.index:\n",
    "    plt.plot(result_table.loc[i]['fpr'], \n",
    "             result_table.loc[i]['tpr'], \n",
    "             label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n",
    "    \n",
    "plt.plot([0,1], [0,1], color='orange', linestyle='--')\n",
    "\n",
    "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "\n",
    "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "\n",
    "plt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\n",
    "plt.legend(prop={'size':13}, loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
